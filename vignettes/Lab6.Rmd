---
title: "lab6"
author: "Gaines"
date: "3/16/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


**1. Section 12.3.3 from your textbook refers to: The problem with replications of a meaningless experiment: ‘alpha and the captain’s age’. The issue here is that if you run an ineffectual experiment enough times you can always find a significant result by chance. The textbook mentions that if you repeat an experiment 20 times, you are guaranteed to find a significant result with .64 probability, and the probability is .92 if you repeat the experiment 50 times.**
**1a. Make use of the rbinom() function to show you can reproduce both probabilities. (1 point)**

```{r}
Ahist <-rbinom(10000,20,.05)
hist(Ahist)
length(Ahist[Ahist>0])/10000
```
The rate of making a type 1 error in this model for 20 subjects (/trials) is `r length(Ahist[Ahist>0])/10000` which is approximately equal to the textbook value of .64.

```{r}
A50hist <-rbinom(10000,50,.05)
hist(A50hist)
length(A50hist[A50hist>0])/10000
```
The rate of making a type 1 error in this model for 50 subjects (/trials) is `r length(A50hist[A50hist>0])/10000` which is approximately equal to the textbook value of .92.

1b. If the ineffectual experiment was conducted 20 times, and there were four groups, and the experimenter would accept a significant result from any of the orthogonal linear contrasts, what would be the probability of finding a significant result here? (1 point)


**The next two questions draw a connection to a technique we have not yet discussed called p-curve analysis (Simonsohn et al., 2014; Wallis, 1942). P-curve analysis is sometimes used for purposes of meta-analyses to determine whether there is “good” evidence for an effect in the literature.**

**2. Consider that a researcher publishes a study showing a significant effect, p <. 05; but, in reality the researcher makes a type I error, and the manipulation did not cause any difference. If many other researchers replicated the study, what kind of p-values would they find? Use R to create a sampling distribution of p-values that would be expected in this situation. What shape does this distribution have? (2 points)**
```{r}
t_results <- replicate(10000,t.test(rnorm(10,0,1),rnorm(10,0,1),var.equal=TRUE)$p.value)
hist(t_results)
```
Looks flat.
3. Now assume that the published result reflects a true effect. Specifically, let’s imagine the study had two groups (between-subjects), with 20 subjects in each group. Assume that scores for subjects are all sampled from a normal distribution, and that group A has larger mean than group B by .5 standard deviations (e.g., Cohen’s d = .5). If many other researchers replicated the study, what kind of p-values would they find? Use R to create a sampling distribution of p-values that would be expected in this situation. What shape does this distribution have? (2 points)

```{r}
t_results <- replicate(10000,t.test(rnorm(20,0,1),rnorm(20,.5,1),var.equal=TRUE)$p.value)
hist(t_results)
length(t_results[t_results>0.05])/10000
```
4. Same as #3, except that we now assume the design has four groups (between-subjects). Assume that group A has a mean that is .5 standard deviations larger than groups B, C, and D. Use R to create a sampling distribution of p-values that would be expected for the linear contrast evaluating the research hypothesis that A > B = C = D. (1 point)

5.  a one-factor between subjects ANOVA with four groups. Run two simulations of the null-hypothesis, one for the omnibus test, and one for the specific linear contrast mentioned above A > B = C = D. Is the probability of rejecting a type I error (for rejecting the null with alpha < .05) the same for the omnibus test versus a specific contrast? (1 point)

